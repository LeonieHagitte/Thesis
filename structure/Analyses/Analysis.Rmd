---
title: "Analysis"
author: "Leonie"
date: "2024-04-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# to clear environment while working
rm(list=ls()) 

usethis::use_git_config(
  user.name = "LeonieHagitte",
  user.email = "leonie.hagitte@student.hu-berlin.de",
  init.defaultBranch = "devl")

```

# Reproducibility 
```{r}
if(!requireNamespace("remotes"))
install.packages("remotes")
remotes::install_github("aaronpeikert/repro")
repro::automate() #creating a Dockerfile.    ####################### BUG ######
repro::use_docker()
repro::use_gha_docker() #GitHub action (GHA) is a cloud service that runs software when certain events trigger it.Add a GitHub Action to build the required Docker image with

# Install or update 'renv' package from CRAN if needed
# Load 'renv' package
library(renv)

# Initialize 'renv' in your project
renv::init()

# Activate the project-specific 'renv' environment
renv::activate()

# Install required packages for your project
#renv::install()

# Update renv.lock file
renv::snapshot()

```

# Model specification
```{r}
model <- "
# Measurement model
y1 =~ x1 + x2 + x3 + x4
y2 =~ x5 + x6 + x7 + x8
y3 =~ x9 + x10 + x11 + x12
y4 =~ x13 + x14 + x15 + x16
y5 =~ x17 + x18 + x19 + x20

# Factor variances
y1 ~~ y1
y2 ~~ y2
y3 ~~ y3
y4 ~~ y4
y5 ~~ y5

# Factor correlations
y1 ~~ y2
y1 ~~ y3
y1 ~~ y4
y1 ~~ y5
y2 ~~ y3
y2 ~~ y4
y2 ~~ y5
y3 ~~ y4
y3 ~~ y5
y4 ~~ y5
"

```

# Data Preparation
## Data enreading
```{r}
library(dplyr)
library(mice)

data <- read.csv('', 
    header = F)
#missing data are coded as -9999, recode to NA
data[data == -9999] <- NA
#I know you can do this in dplyr using some command
#but this is quick and basic
data2 <- dplyr::select(data, 2, 8:10) #change values
names(data2) <- c('X', 'X', 'X', 'X')


md.pattern(hsbwmiss2, rotate.names = T)

```

# checking for the Pattern of Missings
Although it may not be necessary, because the missings are planned, random missings, one could check for the pattern of the 
missing data.
```{r}
library(mice)
md.pattern(data, rotate.names = T)

```

## NAs FIMLn
```{r}
library(lavaan)
model_fiml <- sem('
                # Measurement model
                y1 =~ x1 + x2 + x3 + x4
                y2 =~ x5 + x6 + x7 + x8
                y3 =~ x9 + x10 + x11 + x12
                y4 =~ x13 + x14 + x15 + x16
                y5 =~ x17 + x18 + x19 + x20
                
                # Factor variances
                y1 ~~ y1
                y2 ~~ y2
                y3 ~~ y3
                y4 ~~ y4
                y5 ~~ y5
                
                # Factor correlations
                y1 ~~ y2
                y1 ~~ y3
                y1 ~~ y4
                y1 ~~ y5
                y2 ~~ y3
                y2 ~~ y4
                y2 ~~ y5
                y3 ~~ y4
                y3 ~~ y5
                y4 ~~ y5
              ', data = data, missing = 'fiml', fixed.x = F) 
# fixed.x = F. FIML works by estimating the relationships of the variables with each other and requires estimating the means and variances of the variables. If fixed.x = T (the default), then the variances and covariances are fixed and are based on the existing sample values and are not estimated.
summary(model_fiml)
parameterestimates(model_fiml)

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

# Poweranalyse
```{r}
install.packages('semPower')
devtools::install_github('martscht/stuart/stuart', ref = 'develop')
library(semPower)
library(stuart)
library(lavaan)
```
 
# Poweranalyse - SemPower mit Model
```{r}
powerMI <- semPower.powerMI(
  type = 'a-priori',
  comparison = 'configural',
  nullEffect = 'metric',
  nIndicator = c(4, 4, 4, 4, 4), # Corrected to a single vector
  loadM = list(.5, .6), # Assuming baseline loadings for two groups
  tau = list(rep(0.0, 20), # Assuming intercepts for 20 indicators in the first group
             rep(seq(.1, .5, .1), each = 4)), # Assuming intercepts for 20 indicators in the second group, with increments
  alpha = .05, 
  power = .80,
  N = list(.80, .20) # Assuming 80/20 sized groups for split
)
# Show summary
summary(powerMI)

```
## Results Printed
semPower: A priori power analysis
                                     
 F0                        0.033897  
 RMSEA                     0.058221  
 Mc                        0.983194  
                                     
 df                        20        
 Required Num Observations 622       
                           (498, 125)
                                     
 Critical Chi-Square       31.41043  
 NCP                       21.05165  
 Alpha                     0.050000  
 Beta                      0.197753  
 Power (1 - Beta)          0.802247  
 Implied Alpha/Beta Ratio  0.252841  


# Poweranalyse - SemPower ohne Model für Sample Split
```{r}
ap <- semPower.aPriori(effect = .05, effect.measure = 'RMSEA', 
                       alpha = .05, power = .80, df = 155)
summary(ap)
```
semPower: A priori power analysis
                                   
 F0                        0.387500
 RMSEA                     0.050000
 Mc                        0.823864
                                   
 df                        155     
 Required Num Observations 128     
                                   
 Critical Chi-Square       185.0523
 NCP                       49.21250
 Alpha                     0.050000
 Beta                      0.199807
 Power (1 - Beta)          0.800193
 Implied Alpha/Beta Ratio  0.250242



# Stuart - Item selection
## Sample split
```{r}
library(stuart)
###########################
data()

split <- holdout(data, prop = c(0.8, 0.20), grouping = NULL, seed = 2024, determined = NULL)
lapply(split, nrow) #check size of sample

```

## Genetic Algorithm
```{r}
library(stuart)
# mmas freier in der spezifikation, variabler
# kfold & genetic loop paar mal laufen lassen, für stabile ergebnisse

gene(
  data,                 # Your data frame containing the observed variables
  factor.structure,     # A list defining the factor structure of your model
  capacity = NULL,      # Optional, capacity constraint for factors
  item.weights = NULL,  # Optional, initial weights for each indicator
  item.invariance = "congeneric",  # Specify the type of invariance assumption for items
  repeated.measures = NULL,        # Optional, specify repeated measures design
  grouping = NULL,                 # Optional, specify grouping variable for multigroup analysis
  group.invariance = "strict",     # Specify the type of invariance assumption for multigroup analysis
  comparisons = NULL,              # Optional, specify comparisons for multigroup analysis
  auxiliary = NULL,                # Optional, specify auxiliary variables
  use.order = FALSE,               # Whether to use order constraints
  software = "lavaan",             # Specify the SEM software to be used
  cores = NULL,                    # Number of CPU cores to be used for parallel processing
  objective = NULL,                # Optional, specify a custom objective function
  ignore.errors = FALSE,           # Whether to ignore errors during fitness evaluation
  burnin = 5,                      # Number of generations for burn-in phase
  generations = 256,               # Total number of generations
  individuals = 64,                # Number of individuals in each generation
  selection = "tournament",        # Selection method for genetic algorithm
  selection.pressure = NULL,       # Pressure for tournament selection
  elitism = NULL,                  # Rate of elitism
  reproduction = 0.5,               # Proportion of individuals reproduced in each generation
  mutation = 0.05,                  # Mutation rate
  mating.index = 0,                 # Index of mating type
  mating.size = 0.25,               # Proportion of mating pool size
  mating.criterion = "similarity",  # Criterion for selecting mates
  immigration = 0,                  # Proportion of immigrants in each generation
  convergence.criterion = "geno.between",  # Convergence criterion
  tolerance = NULL,                 # Tolerance for convergence
  reinit.n = 1,                     # Number of reinitializations
  reinit.criterion = convergence.criterion,  # Criterion for reinitialization
  reinit.tolerance = NULL,          # Tolerance for reinitialization
  reinit.prop = 0.75,               # Proportion of population reinitialized
  schedule = "run",                 # Schedule for genetic algorithm
  analysis.options = NULL,          # Additional options for analysis
  suppress.model = FALSE,           # Whether to suppress model output
  seed = NULL,                      # Seed for random number generation
  filename = NULL                   # Optional, filename for saving results
)

```

## Objective-Function
```{r}
# threshhold for reliability
# correlations?
# variance in item difficulty - via intercepts?? -> intercepts  matrix in lavaan 

# Define a matrix for item intercepts per factor
# Assuming a structure of 4 factors with 4 items each for simplicity
interceptsMatrix <- matrix(c(5, 4, 2, 1,  # Factor 1 items
                             5, 4, 2, 1,  # Factor 2 items
                             5, 4, 2, 1,  # Factor 3 items
                             5, 4, 2, 1), # Factor 4 items
                           nrow = 4, byrow = TRUE,
                           dimnames = list(c("Item1", "Item2", "Item3", "Item4"),
                                           c("Factor1", "Factor2", "Factor3", "Factor4")))


fixedobjective(
  criteria = c("rmsea", "srmr", "crel"), #rel ohne"c" für einzelne faktoren 
  add = c("chisq", "df", "pvalue"),
  side = NULL, #can this be specified for certain values?
  scale = 1,
  matrices = NULL,
  fixed = NULL, #weitere function einfügen - if-then function etc. subreliabilitäten 
  comparisons = NULL
)

#Fixed STUART objective function with:

#1 * pnorm(rmsea, 0.05, 0.015, lower.tail = FALSE) + 1 * pnorm(srmr, 0.05, 0.015, lower.tail = FALSE) + 1 * pnorm(crel, 0.8, 0.075, lower.tail = TRUE)




# matritzen mit objectivematrices function
# theoretisch festlegen, oder kombinatorisch/technisch festlegen? Random draws für fit indices? 


#stuart:::objective.preset + interceptsMatrix
#function (chisq, df, pvalue, rmsea, srmr, crel,interceptsMatrix) 
#{
 #   1/(1 + exp(-10 * (crel - 0.6))) + 0.5 * (1 - (1/(1 + exp(-100 * 
  #      (rmsea - 0.05))))) + 0.5 * (1 - (1/(1 + exp(-100 * (srmr - 
   #     0.06)))))
#}



```

## Crossvalidation or kfold-Crossvalidation
```{r}

# Using the 'holdout' function for data split
data(data)
# split was defined above!

########################################################
# Simple example from gene
fs <- list(ra = names(data)[53:57]) # adapt the columns for the respective factor columns
sel <- gene(split, fs, 3, cores = 1)  # number of cores set to 1 - anzahl über N pro gen unsinnig, default nimmt alle cores

############ k-Folding #########################

# erster der holdout wird an kfold weitergegeben

data(data)
fs <- list(ra = names(data)[53:57]) # adapt the columns for the respective factor columns

sel <- kfold('gene', k = 5, #gene/mmas #how to arrive at number of folds?
  data = data, factor.structure = fs,
  max.invariance = "scalar", ## randomly sampled aus derselben population - höher schon besser/ realistisch 
  capacity = 3, seed = 2024, #what does the "capacity" do?
  seeded.search = TRUE,
  remove.details = TRUE,
  cores = 1) #what does the "cores" do?
#########################################################
summary(sel)

# Crossvalidation
crossvalidate(sel, split)

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```
