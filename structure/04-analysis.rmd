# Analysis

## Data Quality 
Careless or inattentive response patterns were analyzed by the ATC items. Furthermore, the data was checked for outliers. Because of the planned random missings in the data, those missings were imputed using full information maximum likelihood (FIML), via 'stuart's' [@schultze2022] access to 'lavaan' [@rosseel2012]. For model estimation, FIML was used as well to handle the missing data. 

## Main Analyses
Algorithm based item selection was done via the R package ‘stuart’[@schultze2022] and the CFA via the R package ‘lavaan’[@rosseel2012]. Inference criteria: Model fit will be assessed using established criteria (e.g.: @hu1999). Comprising of Chi square significance testing as well as a combination of several fit indices, i.e.,RMSEA < 0.05, SRMR < 0.07, CFI > 0.95. Model-specific cutoff values will be considered as well, using the ‘ezCutoffs’ package[@schmalbach2019]

### Rationale for Measurement Model
One decision that needs to be done by the researcher before the item selection with 'stuart', is the design of the measurement model, or how many items per factor the final scale should have.
This scale will be created as parsimonious as possible, while ensuring that there is a real model fit to be estimated. So the decision in this case was of statistical nature, while with three items per factor, the model would have been just identified, four items per factor is the most parsimonious choice, where there is already a real model fit, that can be assessed in the end.

### Meta-Heuristics
Algorithm-based item selection is used to choose the most relevant items, reducing the initial item pool. In classical approaches, items are evaluated within the overall item pool and are then often selected based on their individual properties (e.g. difficulty, discrimination, item-scale-correlations).
Compared to classical approaches, algorithms are more objective and efficient in finding a good or nearly perfect solution with regard to certain criteria [@leite2008; @olaru2015]. Furthermore, some empirical studies suggest that the use of algorithms leads to similar or better results in scale construction than traditional approaches [@sandy2014; @schroeders2016; @olaru2021]. The automated approach takes the opposite perspective to the classical approach, the one of meta heuristics, by repeatedly estimating CFAs for a multitude of possible item-combinations [@schultze2017]. Thus, a pool of items with some constraints and the goal to find the one combination that best fits the suggested purpose (e.g. equation 1) of the final scale is estimated [@schultze2017].Thus, the selection of items and construction of a questionnaire can be viewed as a combinatorial problem, like the knapsack problem (“Choose a set of objects, each having a specific weight and monetary value, so that the value is maximized and the total weight does not exceed a predetermined limit”)[@schroeders2016, p. 4; @kerber2022; @schultze2017].
\begin{center}
$\Phi = F(\textrm{RMSEA}) + F(CFI)+ F(\textrm{SRMR}) $ (1)
\end{center}
'Stuart'[@schultze2022] can construct subsets from a pool of items by using ant-colony-optimization, genetic algorithms, brute force, or random sampling [@schultze2017]. Those meta-heuristics like are utilized to handle these combinatorial optimization problems. 
For this study, a set of 20 items from a set of 71 items is selected, to form a questionnaire. The data literacy self rating scale is optimized for model fit criteria (RMSEA, SRMR, CFI). Those criteria will be defined in the objective function (equations 1 & 2) in ‘stuart’[@schultze2022,@schultze2017]. 

We use the genetic algorithm of 'stuart' for the item selection. Genetic algorithms are based on Darwinian evolution principles – selection, crossover, mutation and survival of the fittest [@holland1992; @schroeders2016). With the genetic algorithm, the initial set of 71 items is to be reduced based on the evolutionary process of selection, but opposing to evolution with a goal: A near-optimal "solution". The survival of an item is determined by its quality (called “fitness”)[@galan2013]. The algorithm is build on two processes: Variation (i.e. recombination and mutation) and selection. Variation rewards diversity and innovation of items, whereas selection rewards quality or fitness. The algorithm links "genes" (i.e. items), that represent a certain variable, to a "chromosome" (i.e. a set of items). A predefined number of chromosomes are randomly generated from the 1st generation (i.e. the original item pool). The algorithm tries to maximize the psychometric quality of the "chromosomes"(i.e. item sets) by evaluating the "chromosomes"(i.e. item sets) against a “fitness”function. Based on this fitness function, the fittest "chromosomes"(i.e. item sets) of each generation are determined, which then form the basis for the next generation (forming the selection process). The process of variation establishes genetic diversity and mutation within the generations by spontaneously exchanging items within a scale or between two scales, which adds a degree of randomness to the selection process. This is done a predefined number of iterations. Thereby, the fittest "chromosome"(i.e. set of items), with the highest quality, is to be identified [@schroeders2016]. 

## Validation
The provided sample is divided into two subsets (i.e. training data and test data) using the ‘holdout' function in ‘stuart’. The specified item-selection procedure is applied to the training data. The training data is undergoing k-fold cross validation (*k*=3), using the ‘kfold’ function in ‘stuart’. Those k-folded selections are then again iterated three times, to enhance the stability of the solution even more. The other sample, the test data, is used for evaluation of the final models performance, as well as the latent correlations with the convergent measures.
Validation with the test data is conducted (using an MG-CFA in ‘lavaan’) to assess the invariance of the measurement models between the training and testing datasets. Invariance levels are assessed using the criteria of @chen2007. Invariance is necessary to claim that the scale validation has worked.

## Exploratory Analyses
Because the complexity of the model, as well as the several objectives of the initially planned objective function, the genetic algorithm had problems converging into a stable solution, let alone a solution with sufficient model fit. Therefore some objectives were dropped (the composite reliability and the varying item intercepts per factor), in favor of model fit. Different solutions were systematically explored, dependent on the estimator (MLR or WLSMV) and the respective data structure (data treated as metric or ordinal data), as well as on the objective function, to lead to the best solution. Furthermore because of convergence issues the data was checked for multicolinearity. 
