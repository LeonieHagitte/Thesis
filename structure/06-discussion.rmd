# Discussion

## Summarising the results

Everything worked - what do I need to report?
First, report on the three core decisions and how the solution was created, whether it is stable, and how it was validated. The final variant is then reported exactly like a CFA (e.g. Jackson et al., 2009). To have a clear structure, answer the following questions:
How large was the original item pool and how was it created?
What is the structure of the scale?
Which algorithm was used (or bruteforce)?
Which objective function was used?
How stable is the final variant?
How was the final variant further validated (e.g. crossvalidate, k-fold)?


## What does it all mean / "Why?"

- Start with the research question
  - Maybe then towards the hypotheses
- connecting findings to the related theories
- very related/ current literature first, than broader is possible
- When discussing the why - be careful, because you didnt test that

## Limitations
- sample
- content validity
- DIF?
- psych science - authors guide to generelizability
- attempts to control for limitating factors
- dont include to general/ broad critiques, but special one for my own study

This study's results should be interpreted with the following limitations in mind. 
As shown in the demographic variables, the sample of this study deviated from the 
general public in several points. Thus, this study might not have reached a representative sample
and therefore lack generalizability. For example the distribution of the occupations, in which the 
participants work, show that they are not evenly distributed. There is some clustering in **"Gesundheit, Soziales, Lehre und Erziehung"**, **"Buchhaltung, Recht und Verwaltung"**, **"Kaufm√§nnische Dienstleistungen, Vertrieb, Tourismus"** and especially in **"Naturwissenschaft, Geografie und Informatik"**. This speaks to a selection bias in the data, as those could be professions, held by people, who are more interested in the topic of data literacy, but who are also more likely to be reached with the acquisition methods, used in this study. It is to be kept in mind that this influences the 
item pool selected, because this is specifically trained on the sample of this study. 
From a theoretical perspective, data literacy is such a heterogeneous construct, that one could of corse incorporate more aspects of data literacy in the items of the questionnaire, making it more reflective of the whole concept and increase its content validity. Ideally this draft of a questionnaire for data literacy would be expanded with items on such areas, giving it a specific focus, much like a plug-in system. This then would not adhere as closely to the idea of a parsimonious questionnaire but could be a pratical solution for the need of more specific questions, or more difficult items.
Furthermore the training data set and the testing data set are of different size, which 
can influence the MI testing (Chen,2007). Additionally, the sample sizes, although appropriate, ideally could have been larger and are on the lower threshold of the prior poweranalysis (e.g., Kass andTinsley, 1979; Hu and Bentler, 1999). 
Although the questionnaire exhibited good model fit, it is to be kept in mind 
that algorithm based item selection is essentially a heuristic approach and does not 
always result in the best solution there is. 

## Future directions

########################################

Construct validity is evaluated through confirmatory factor analysis (CFA), using MLR as estimator, as well as correlation analyses with related constructs

- what to optimize the scale for?
- dynamic fit indices
- factors 4 and 5
    - adaptive testing/ IRT
        - dimensionality assumption and computationally intense
    - CART - tree based adaptive testing (classification trees) always binary split
        - gini index to identify the cut off 
        - POMP method - for differing number of answer formats
- residuals correlates 
- heterogeneity of construct 

The heterogeneous nature of the construct complicates global instrument development and understanding across all participants. The measure is designed for citizens, potentially limiting discrimination at higher item difficulties or among more literate participants, a direction we aim to improve in future studies.


Noteworthy is the inherent approximate, rather than deterministic, nature of metaheuristics (Schultze & Lorenz ,2023; Blum and Roli, 2003).