---
title: "Development of a German Instrument for Self-Rated Data Literacy"
author: "Leonie Hagitte"
date: "`r Sys.Date()`"
output: pdf_document
site: bookdown::bookdown_site
documentclass: article
bibliography:
- packages.bib
- literature.bib
csl: apa7.csl
link-citations: true
description: ''
fontsize: 12pt
linestretch: 1.2
geometry: left=3.9cm, right=3.3cm, top=2.5cm, bottom=3cm
papersize: a4
classoption: twoside
repro:
  packages:
  - devtools
  - here
  - aaronpeikert/repro@adb5fa56
  - bookdown
  - usethis
  - gert
subtitle: "An Algorithm-based Approach to Scale Development"
---

# Abstract {-}

Placeholder



<!--chapter:end:index.Rmd-->

# Acknowledgements {-}

I dedicate this thesis to 

I want to thank my advisers, Prof. Martin Schultze, Prof. Timo Lorenz, and Prof. Manuel Völkle for their time and patience, and my friends for their resourceful advice:

\newpage\null\thispagestyle{empty}\newpage

<!--chapter:end:acknowledgements.Rmd-->


# Background

Placeholder


## Conceptual Integration  
### Comprehension 
### Evaluation 
### Integration  
### Communication  
### Statistics 
## Delineation from other concepts - The nomological net   
## Discrimminant Constructs  
### Need for Cognition  
### Opennes to new experiences   
### Conscientiousness  
## Aim of the Study  

<!--chapter:end:02-background.Rmd-->


# Methods

Placeholder


## 2. Stage Two: Item Selection and Construct Validity
## 3. Stage Three: External and Construct Validity Testing 
## Item Creation  
## Rationale for Measurement Model
## Sample 
## Open Science Standards 
## Procedure
## Instruments  
### Measuring Data Literacy
### Measuring Self-Efficacy to Information Behavior
### Measuring Need for Cognition
### Measuring Self-Perceived ICT Competency
### Measuring Openness and Conscientiousness

<!--chapter:end:03-methods.Rmd-->

# Analysis

Algorithm-based item selection is used to choose the most relevant items, reducing the item pool. Unlike classical approaches that consider items based on their individual merits, heuristic item selection algorithms aim to enhance the psychometric properties of a set of items within predetermined constraints (Schultze, 2017). The sample is split into training and test datasets to evaluate solutions against an objective function consisting of model fit criteria and composite reliability. In automated item selection, items can be chosen as sets that meet specific criteria. Those criteria will be defined in the objective function in ‘stuart’ (Schultze, 2020). I want to optimize the final model for model-fit and reliability (RMSEA, SRMR, CFI & McDonald's $\omega$ ) as well as variability in the difficulty of items.

Relationships between the newly created measure and related constructs are hypothesised. Construct validity is evaluated through confirmatory factor analysis (CFA), using MLR as estimator. and correlation analyses with related constructs. Crossvalidation and measurement invariance tests are also conducted.
I expect the final questionnaire to correlate moderately up to highly positive with the SWE-IV-16 (Behm, 2018), measuring peoples ability to engage in information behaviour. I expect a moderate, positive correlation of the final scale with the five general items of the ICT-SC25 (Schauffel et al., 2021). I expect a small positive correlation with the NFC-K (Beißert et al., 2015), assessing the Need for Cognition (NFC). I also expect small positive correlations with openness and conscientiousness of the BFI-10 (Rammstedt et al., 2014). 
The provided sample will be divided into subsets using the ‘holdout' function in ‘stuart’. The specified item-selection procedure will be then applied to the training dataset first. It will then be tested on the testing dataset. 
Validation will be conducted using the ‘crossvalidate’ and/or the ‘kfold’ function in ‘stuart’ to assess the invariance of the measurement models between the training and validation datasets. Invariance levels will be measured with  the ‘max.invariance' function. Invariance will be necessary to claim that the scale validation has worked.  
The final item selection will be determined by the highest value on the objective function in the multiple-group SEM, while ensuring 'max.invariance' between the training and validation data, as well as in a possible k-fold crossvalidation.


residuals
correlates or the residuals for the adjacent constructs

<!--chapter:end:04-analysis.Rmd-->

# Results

## Demographic Results  

On average, participants were working (M/SD). On average, participants were studying (M/SD). Descriptives and Correlations 
Table XX 
presents descriptive statistics, McDonald’s $\omega$ ,
Cronbach’s $\alpha$ and the correlation matrix for the respective variables.  
The data literacy scale correlated XXX with the SWE-IV-16(r = , p ). The data literacy scale correlated XXX with the NFC-K(r = , p ). The data literacy scale correlated XXX with the the general items of the ICT-SC25(r = , p ). The data literacy scale correlated XXX with the openness of the BFI-10(r = , p ). The data literacy scale correlated XXX with conscientiousness of the BFI-10(r = , p ). The xxx correlations (r = , p ) between the newly created scale and the SWE-IV-16, NFC-K, the general items of the ICT-SC25 and openness and conscientiousness of the BFI-10,respectively, indicate the data literacy scale measures #a similar, yet distinct concept#.

## Model Fit and Latent Structure in the Construction Sample  

The Algorithm selected 20 of the 71 original items representing the five factors Comprehension, Evaluation, Integration, Communication and Statistics with four items each (Figure X). The final solution exhibits good model fit with Satorra-Bentler-$X^{2}$ (XXX, N = XXX) = XXX, p = XXX,CFI = XXX, TLI = XXX, SRMR = XXX, RMSEA = XXX, 90%-CIRMSEA [XXX; XXX]. 
Standardized loadings of the factor Comprehension ranged from 0.XX to 0.XX. For the factor Evaluation loadings ranged from 0.XX to 0.XX. For the factor Integration loadings ranged from 0.XX to 0.XX. For the factor Communication loadings ranged from 0.XX to 0.XX. For the factor Statistics loadings ranged from 0.XX to 0.XX.
All factor loadings including standard errors can be found in the Supplementary Material. 

## Model Fit and Latent Structure in the Validation Sample
Cross-validation with the second half of the data indicated that the assumption of XXXX measurement invariance holds across the XXX subsamples: $X^{2}$(XXX) = XXX, p < XXX, CFI = 0.XXX, SRMR = 0.XXX, RMSEA = 0.XXX; $X^{2}$ = XXX, df = XX, p = 0.XXXX. 




<!--chapter:end:05-results.Rmd-->


# Discussion

Placeholder


## Summarising the results
## What does it all mean / "Why?"
## Limitations
## Future directions

<!--chapter:end:06-discussion.Rmd-->

# References {-}

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown', 'repro', 'here', 'usethis', 'gert', 'credentials'
), 'packages.bib')
```

<!--chapter:end:references.Rmd-->

