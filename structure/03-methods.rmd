# Methods

## Item Creation  
Prior to the item creation a review of the literature was done. Since the idea was to create a self-report questionnaire, the indicators of the latent constructs were decided to be subjective indicators or Q-data[BÜHNER]. Furthermore it was set that the target group for the questionnaire are German speaking citizens. There were no clear restrictions regarding age or education, other than the participants being of legal age and that the questionnaire should not be directed at professionals in terms of data literacy, or highly educated people.

The item creation itself was oriented towards the Act-Frequency-Approach [@buss1983], thus the prototype approach. 
I started with thinking of frequent, relevant behaviors, convictions or believes reflecting the factors of data literacy, hence being prototypical of those latent factors.
For the *Comprehension* factor that could be recognizing whether the interpretations of others fit the available data, or recognizing when one is presented with contradictory information or understand the information a graphic contains, when data is presented as a graphic.
Regarding the *Evaluation* factor that could be for assessing the credibility of information, to consider the reputation of the source. As well as being aware that publishers' own interests can influence the published information or to check information by comparing several sources with each other.
The *Integration* factor could be represented by dealing with information that challenges ones views or consciously incorporating data-based findings into ones opinion-forming process. Additionally it could also manifest itself in changing ones mind if new data calls it into question.
For the *Communication* factor, that could be represented by feeling confident in presenting data in visual formats in a way that is understandable for different target groups. But also to feel confident in expressing ones point of view in discussions or being able to summarize the most important information from data sets.
As for the *Statistics* factor, this could be represented by knowing how to distinguish between causality and correlation or having analyzed data sets using simple statistical methods. It could also mean to know how to prevent systematic errors in data collection.

That way i created over 100 potential items, that were then refined in terms of wording, structure but content as well. 
I avoided inversely worded items, and decided to not ask for specific examples, because those might enhance the difficulty of the respective items, depending on the personal background of the person answering the question. 
Additionally, I made sure that items were only ever asking for one behavior, conviction or opinion at once. 
Overall I tried to formulate the items as easy and understandable as possible. 
Ten cognitive interviews were held to refine those potential items and to confirm the prototypicality of the behaviors etc. asked in the items. 
The cognitive interviews comprised the think-aloud-technique as well as probing, to get an understanding of how the items are understood, what comes to mind when reading the items and whether the items really ask for relevant behaviors [@fowler1995]. Furthermore, that way unclear formulations or difficult wordings could be resolved.
The interviews were administered iteratively to refine the items consecutively. 
In the interviews it became apparent, that especially the degree to which people can relate to the factors four and five differed heavily. This was expected, since those producer factors are also considered to play a lesser role in the every day live of citizens. It also turned out that some words like "data", "source" or "information" are understood differently regarding the personal background sometimes. 
The age of the interviewed persons ranged from 21 to 66. Three of the interviewed persons were men, the other seven were women. The occupations included, for example, students, construction managers, and nurses working in intensive care units. After the cognitive interviews of the 118 potential items, 71 were left. A list of all 71 items can be seen in table X.

## Sample  
The participants are recruited through a combination of personal and professional networks, along with outreach on several online social media platforms (e.g. Instagram, LinkedIn, Whatsapp, Telegram and via e-mail). Conducted in German, the participation in the study was entirely voluntary, with no external incentives provided. We conducted a-priori power analysis to determine the necessary sample size for the structural equation modelling. We used the ‘semPower’ package in R [@moshagen2024] and also took a look into studies with similar goals and methods. The power analysis gave an analytical estimate for *N*=645, and a simulated estimate *N*=613, for the respective measurement model. In the literature sample sizes of *N*=500 up to *N*=1000 could be found [@algner2022; @remmert2022; @schneider2024]. So the optimal sample size, we are aiming at, lies somewhere between those numbers.

Participants had to be of legal age to be included in the study. Furthermore, attention check questions are included (three instructed response items and one seriousness check item at the end) within the survey to assess participants' attentiveness. Participants who fail to correctly answer two out of the four attention check questions will be excluded from the analysis.

The following characteristics of this study's sample will be made with referral to the respective statistics in the German population of 2022.
The sample for this study comprised *N* = 616 participants. Within the sample, 48,3% identified as female(50,65%), 50,2% as male (49,35%), and 1,5% did not identify with binary gender categories [@StBA2024a]. The average age was 40 years (*M* = 44,6)[@StBA2024b], with an average age of 39 years (*M* = 38.79; *SD* = 14.5) amongst women (*M* = 45,9)[@StBA2023a] and 42 years (*M* = 41.96; *SD* = 14.23) amongst men (*M* = 43,2)[@StBA2023a]. The average age of people not identifying with binary gender was 28 years (*M* = 27.63; *SD* = 11.0).  Regarding education, participants exhibited a [insert educational level- specifying the range or types of educational levels observed in the sample].
Of those participants, who indicated they were in an employment, 64.88% had a full time employment (51,75% of the women indicated full time employment, 77,73% of the men indicated full time employment), at the time (65,15%; Men = 42,40%, Women = 22,75%)[@StBA2023b; @BfA2024], 35.12% indicated a part time employment (48,25% of women indicated part time and 22,27% of the men), at the time (28,22%; Men = 6,16%; Women = 22,06%)[@StBA2023b; @BfA2024] and 13.52% had no work at the time of the survey (6,63%)[@BfA2024]. The study encompassed every sector within the occupational classification at least once [@BfA2024]. 25.2% of the participants indicated that they were students at the time of the survey (3,39%)[@StBA2024c].

## Open Science Standards 
This project uses the reproducibility workflow proposed by @Peikert2021. 'Docker' and 'renv' work together to create a reproducible and portable environment. 'Docker' captures the complete software stack, while 'renv' focuses on
managing R package dependencies and providing a clear documentation of the R
package environment. This combination ensures that the analysis can be easily
reproduced and shared with others in a reliable and transparent manner. It is to be mentioned, that the 'repro' package from @Peikert2021 has slightly changed in its functionality, namely that it does not ensure any longer, that old versions of the used software get re installed. Furthermore we used the 'reproducibleRchunks' package from @brandmaier2024. This package enables the verification of computational results in R for reproducibility, ensuring that the same script with the same data produces identical results across different computers or at different times. When knitting the respective document, one can see the results for the respective chunks, as to whether they are reproducible or not.
The study was preregistered at Zenodo (DOI:10.5281/zenodo.11196495).

## Procedure
A cross-sectional online survey is used to examine a sample from the general population. Participants complete the Self-perceived Data Literacy Scale alongside demographic questions and additional validation measures. Survey questions of each measurement are randomized for each participant to minimize order effects and response biases. To shorten the overall length of the assessment the questions in each factor of the data literacy questionnaire are randomly selected for each participant. That way each participant only answers half of the possible items, the other half are planned missings. I treated the first 25 participants like a pilot, to check for potential problems in the survey (like length, spelling mistakes that have been overlooked etc.).

## Instruments  
### Measuring Data Literacy
On Data Literacy the participants will be asked to answer 71
items. Each participant will answer 38 items of the 71 that are randomly selected.
To answer the items, respondents indicate their agreement on a five-point Likert
scale (1 = "strongly disagree", 2 = "somewhat disagree", 3 = "neither agree nor
disagree", 4 = "somewhat agree", 5 = "strongly agree”) with a “don’t know”
option.

### Measuring Information Literacy
The SWE-IV-16 [@behm2018] (McDonalds $\omega$ = .91; Cronbachs $\alpha$ =.91) assesses the self-efficacy beliefs of adolescents and adults in their ability to engage in information behaviour. This
questionnaire measures the process model of information-related problem-solving
[@brandgruwel2009]. In our study this construct is used as a proxy for information literacy.
It consists of 16 statements addressing self-assessed
abilities in searching for and evaluating information, as well as managing
information searches effectively. Each statement begins with "When I search for
information on a topic or a specific question..." and respondents indicate their
agreement on a five-point Likert scale (1 = "strongly disagree", 2 = "somewhat
disagree", 3 = "neither agree nor disagree", 4 = "somewhat agree", 5 = "strongly
agree”). The total scale value is computed as the arithmetic
mean of the items, which may be inverted if necessary. Calculation of the total value
requires valid responses to at least 12 of the 16 items. The final questionnaire is expected to correlate moderately up to highly positive with the SWE-IV-16 [@behm2018], measuring peoples ability to engage in information behaviour.

### Measuring Need for Cognition
The NFC-K [@beißert2015] (McDonalds $\omega$ = .62; Cronbachs $\alpha$ =.60) is a tool used to assess the
NFC through four items, which represent two facets: "engagement" and “joy". The
NFC-K is measured with a seven-point response scale, ranging from "strongly
disagree" (1) to "strongly agree" (7), with a "neither" option in the middle. The
German version of the scale is adapted from the original English scale by @cacioppo1982 and translated by @bless1994. To determine an individual's NFC score, a mean value
(scale value) is computed from the four raw score points of the responses. The
resulting mean values range between 1 and 7. A small to moderate positive correlation with the NFC-K [@beißert2015] is expected, assessing the Need for Cognition (NFC).

### Measuring Technology Competency
To assess self-perceived competence in using information and
communication technology (ICT), the five general items of the ICT-SC25 [@schauffel2021] will be used (McDonalds $\omega$ = .93; Cronbachs $\alpha$ =.93). The ICT-SC25 is a scale consisting of 25 items designed to
assess self-perceived competence in using information and communication
technology. It is available in both German (ICT-SC25g) and English (ICT-SC25e). The
scale measures general and domain-specific ICT competence, including
communication, processing and storing, content generation, safe application, and
problem-solving skills. Items are measured using a six-point fully-labeled Likert-type
rating scale ranging from strongly disagree (1) to strongly agree (6). Researchers can choose to 
utilise either the entire scale or individual subscales based on their specific research objectives. The ICT-SC25g/e
is applicable for both manifest and latent analysis. Manifest scale scores for the ICT-
SC25g/e are calculated separately for each subscale by computing the unweighted
mean score of the items within each subscale [@schauffel2021]. A moderate, positive correlation of the final scale with the five general items of the ICT-SC25 [@schauffel2021] is expected.

### Measuring Openness and Conscientiousness
The BFI-10 [@rammstedt2014] will be used to assess
personality based on the five-factor model. Only the items on openness (McDonalds $\omega$ = .63; Cronbachs $\alpha$ =.63) and conscientiousness (McDonalds $\omega$ = .56; Cronbachs $\alpha$ =.56) were assessed.
The items are answered on a five-point rating scale from "strongly disagree" (1) to
"strongly agree" (5). To measure the respondent's individual traits on the two
personality dimensions, the responses to the two items for each dimension are
averaged. First, the negatively worded item is recoded (items 1, 3, 4, 5, and 7), then
the mean value is calculated for each dimension from both the recoded and non-recoded items. The values for the five dimensions range from 1 to 5 (see @rammstedt2007 for reference values). Small to moderate positive correlations with openness and conscientiousness of the BFI-10 [@rammstedt2014] are expected. 


